---
title: Title of the Ethics Paper Goes here
mainfont: DejaVuSerif.ttf
sansfont: DejaVuSans.ttf
monofont: DejaVuSansMono.ttf 
mathfont: texgyredejavu-math.otf 
---

Introduction
============

This article proposes an ethics of “Human Computer Interaction”. We bring together philosophical sources and existing references to *ethical thinking* in HCI. The development of this project stems from *a need to cement the existing understanding of the pro-social use of computational technologies*. "Interaction" is the central theme, which we use towe develop *a position that can be used holistically to theorise and structure interaction with and within intelligent systems*.  The impetus for our work is the awareness that humanity has entered into a new historical era, whether we think of it as the anthropocene, the information age, a new Industrial Revolution, or, indeed the beginning of the Novacene (Lovelock). Many of the historically-novel and existentially-salient aspects of life in the 21st Century have a legacy going back to the industrial revolution and the Enlightenment. However, the theoretical structures left to us by our forebears are as out-of-date as the steam engine and the guillotine. To ameliorate the harms and capitalise on the benefits of our post-modern condition, we need a way to understand human-computer interaction ‘at scale’. "Philosophy of technology" will run throughout our work here, though we do not re-theorise it here (rather, we provide a brief recap of Simondon, Heidegger, Steigler, Simondon, et al., in the Discussion).

**We focus on the following questions:** (1) How are ethics used and applied to contemporary information systems? (2) How do the systems 'react back' on our ways of thinking about things? (2) And, vice versa, because of AI: how do computationaly systems apply the ethics that I applied, or develop ethics of their own? What is lost in the middle? What could change for the better? (3) Lastly, what is the overal narrative or genre in which these questions can be discussed and pursued further? (E.g., Law? Philosophy? Computing? Religion? Science Fiction?)

==Further notes: [How do we use ethics](https://logseq.com/page/how%20do%20we%20use%20ethics), [Motivation](https://logseq.com/page/motivation)==

Method
======

We survey references to computing and machinery within philosophy, and references to ethics and philosophy within computing literature and references. Based on aligning this material we propose ethical guidelines - which in themselves present a worldview (although it is often only implicit). The central contribution of this article is an ethical taxonomy that works for the future given the massive development of artificial intelligence and its pervasiveness. It will take into account: **1)** the interfaces in which ethics can be applied (species and robots); **2)** the change in behavior that comes from the 'benefit' to make people interconnected as a global mind; **3)** until what point social interaction can change and *exist*; **4)** reference and build on top of existing surveys (e.g. **Machine Implementations of Ethics** and **[Peer Production: A Modality of Collective Intelligence](https://www.scholars.northwestern.edu/en/publications/peer-production-a-modality-of-collective-intelligence)**). We will build on the proposed terminology: *(1) Of ethical impact agents; (2) Implicit ethical agents; (3) Explicit ethical agents; (4) Fully ethical agents; (5) How are ethics really used in systems - that in itself.*

Scope
=====

*Human-computer cocreativity* (HCCC) is a motivating domain. In HCCC, creativity is attributed to collectives.  Here, we want to look in more detail at what what humans co-create computational media.  While our focus is on modern computing machinery, in order to cast a wide net we think about computers as ‘effective systems’, or even just as machinery.  Our survey will look both philosophical and computing work within the following thematic areas (*Why do we need this?*) **1)**  What should we understand by ‘an ethical use of computer technology’ (e.g., the so-named *slave/master paradigm* — which terminology has itself been criticised)? and **2** How can our reflections on HCI and HCCC build a foundation for the ethical uses of intelligence that work in the future?


# 1.0 Philosophical foundation for a contemporary ethical practice 
## 1.1 Western philosophy and ethics definition

Human beings have always been interested in categorizing their behaviour. Classification and criticism, personal and interpersonal, about actions taken towards the world. When this criticism is made, there is no way that it will not be realized subjectively (lens argument), even if it embraces generalization. This recursive feedback to outselves has allowed the analysis and assessment of actions that we deem meaningful - or that others consider significant in us - originating fundamental positions for human understanding from the human. It is not in vain that *ethics* derives from the Greek "ēthikós" (ἠθικός) that means "relating to one's character" - as a relational loop. Indeed, a deeper etymology points to both habit and environment; ἤθεα meaning “accustomed place” (as in ἤθεα ἵππων “the habitat of horses”, Iliad, 6.51115.265).  This points to an "ethological" side of "ethics", which is pursued, e.g., by Spinoza (as per Deleuze's reading). Importantly, our environments include *others* and provide grounds for interaction. Just as I consider myself, I can imagine the way others consider me, consider them, and develop collaborative processes for all this. Right here comes ethics and the way it will happen in society. Paul and Elder (2003) define *ethics* as: **a nondetermined set of concepts, principles and metarules that guide us in determining what behavior (acting towards) helps and/or harms sentient creatures.** Having a fundamental but abstract definition that allows us to develop ethics helps to create a relationship structure.

==Further notes: [1.A](https://logseq.com/page/1.a), [Phenomenology and being](https://logseq.com/page/phenomenology%20and%20being), [Ethics and Ethology in Homer](https://logseq.com/page/ethics%20and%20ethology%20in%20homer)==



### 1.1.1 Responses in computing literature

These days, given the transmutation of information and increased reception of things around us, technology can even help us to revive and rethink the way these thoughts affect us culturally. For example the work of Kantosalo and Schneiderman: using computers to help us "think" about creativity. (Anna Kantosalo and Ben Schneiderman (using computers to think about ‘creativity’))

## 1.2 Holistic views of philosophy 

Philosophy is inherent in the complexity and uniqueness of each culture. When applied from a broad point of view and not only focused on the human, it can conquer and integrate as its baggage other types of entities such as artificial intelligences or non-human organisms. As is the example of panpsychism (Seager 2006), where it is common to have a naturalistic account of the world, for
only from the point of view of some such account
can the issue of mind’s place within the natural
world arise. Even the *philosophy of mind* has in itself a position. Not only as a philosophy, but as a starting point for philosophy to begin. There is a beginning that points to a vision in which all the positions taken before that thought make sense. When using positions that are global in terms of beings that exist, an ethical framework forces us to consider computers as *creatures*. 

==Further notes: [Holistic views of philosophy](https://logseq.com/page/holistic%20views%20of%20philosophy)==

### 1.2.1 Responses in the computing literature

Given the holistic point of view, which in itself is linked to space and context - the reflections made today often map the past. The way we relate - to each other, to artificial elements and the environment - is what has been driving us, we might want not only to map but also revisit past. 


# 2.0 Embodied cognition, social intelligence, collective intelligence 

Given the survey of the philosophy in the previous sections, structured the role of the being in nature, we focus on his knowledge, how he can inform the development of thinking machines and to what extent some of these terms are always intrinsically social. It is based on 1) the work on Kant's interpersonal relationship; the way evolution is seen through Freud's eyes; 3) the extent to which we should and can be analytical in developing an ethical stance towards 'the whole', with Carl Jung; 4) focusing on recent developments like the Helmholtz Machine and active inference - as well as the work done in 2021 in these mentioned fields.

By focusing on cognitive science and its limits, the limits of philosophy are established, while often based solely on perception, and a body of arguments is created to serve as a starting point for taxonomy. Where given recent discoveries, the thinkers mentioned intersect with science. Here a starting point is defined for what mind means; what it means to have one; how can we catalog various species of minds for the future; how these interact; what points of view exist (functionalists, patternists, etc.) that we can use as starting point to justify our relationship with the taxonomy (position towards) - also listing relationships between them.

## Responses in the computing literature

How today's computing uses our position: 1) how what we call as *creativity* is social and socially **computational**; 2) how virtual distributed agency and behavior is exactly what is happening int he physical world; 3) how are current approaches to building thinking machines that can approach this (e.g. bioinformatics and computational neuroscience); 3) how Cyborg manifestos are like this ethical proposal, e.g. Donna Haraway, and current work on computers and interaction (mention Anna's paper here). How really, AI is truly social and exists as a potential force for "good" (if that is understood as *pro-social*).


# 3.0 Reprise: Evolution regarding all of these 

Histories of the evolution of intelligence (sociality & tools being key focal points). Theories of evolution, e.g., Baldwin (and later derived work by Hinton and others). Derrida's concept of [différance](https://en.wikipedia.org/wiki/Diff%C3%A9rance#Life_and_technics). Based on the points raised as discussion in the previous sections mention until what point evolution plays a or the major role. How future AIs will encompass some of the evolutionary paradigms we faced and how our ethics project will not be ruined in future decades - getting to the point where evolution might be quicker virtually (as a *type* of evolution).

==Further notes: [Language is mapping thinking](https://logseq.com/page/language%20is%20mapping%20thinking), [Evolution](https://logseq.com/page/evolution)==

## Responses in the computing literature

The mapping of evolutionary techniques and parallel thinking (social behavior also mapped and check if this doesnt exist elsewhere). Metacognition as assessment and metamemory as understanding if we remember is true and the access we can have. Cognitive psychology approaches to AI (maybe connect this to reinforcement learning and behavior?) Current approaches to model ethics in computers as values and the ones that model only the environment that will give rise to the values in the first place (2021 literature) Predictive Processing and Active Inference (bring embodiment to the discussion here); if "Ethical AI" is important or a more globalist perspective: Notice that now that computers are involved, the way we think about ethics and so on is likely to change.

# Ethics Taxonomy

An ethics taxonomy is presented as a mapping of values and positions we and machines can take now and in the future regarding the questions raised such as: **1)** how can we and machines establish a true and *positive* relationship with each other in points such as **1.1)** designing other machines or (artificial) humans; **1.2)** impact other elements of the society; **1.3)** change ourselves; **2)** what does it mean to be ethical towards something using an abstract definition; **2.1)** what being means comes from above; **2.2)** towards something also comes from above; **2.3)** abstract definition comes from language also from above; **3)** define and utilize this taxonomy based on interaction, social behavior, design and engineering, be computing␣platform-agnostic and topic-agnostic, and how machine ethics is right or wrong as a separare domain, how to imply ethics works and doesn't work; propose meta-ethics guidelines on how can we create ethical guidelines that create ethics.

# Discussion

Have we learned anything that's relevant for practice? Maybe here is a good time to return to some of the debates that look at "creativity" in a more mainstream sense, e.g., Anna Kantosalo and Ben Schneiderman about creative systems and social inclusion vs  exclusion? From the point of view of "Methods", hopefully we will have clarified at the start why we think this sort of activity could lead to new insights! We will build a thought experiment in the text to utilize the raised taxonomy. 

As related work we should specifically engage with **Floridi**:

> With distributed agency comes distributed responsibility. Existing
> ethical frameworks address individual, human responsibility, with the
> goal of allocating punishment or reward based on the actions and
> intentions of an individual. They were not developed to deal with
> distributed responsibility.

This seems like an important point: we'll need new (not necessarily
"agential") ways to think about ethics.  It seems useful to apply this
in somewhat more general terms about "intelligent systems" --- or just
"systems with emergent properties"; so, if distributed agents produce
e.g., environmental degradation, that’s not ethical, and the system
as a whole "should" find ways to improve its behaviour. This sort of
thing is thought about in Elinor Ostrom’s economics. A particular concern of Taddeo & Floridi here seems to be "autonomy"
of AI, and "self-determination" of humans. But in the case of HCI/HCCC
it\'s not totally clear that either of these criteria apply. In HCCC
it\'s much closer to
[anthropotechnics](https://www.wired.com/beyond-the-beyond/2015/09/peter-sloterdijk-anthropotechnics/).

==Further notes: [Case studies reprise](https://logseq.com/page/case%20studies%20reprise)==

## Related work

Alongside philosophers mentioned in the Introduction we can mention books such as ("Creativity and Ethics", "Technology and the virtues: A philosophical guide to a future worth wanting", "Made by Humans", "Machines that Think", "How AI can be a force for good", and connect all these topics with political, scientific and visionary points that authors made in time.

# Conclusions

As a result of the theoretical paper presented we will build answers to the following questions: **1)** **How can I practically engage with these issues as a computer science researcher?**; **1.1)** as a researcher how can I fit inside an ethical framework without disrupting my day-to-day way of work, that in itself guides me as a railway - and this day-to-day should also work within the following decades; **1.2)** how can this ethical framework overcome me as a CS male white european guy and still work for me as a CS male white european guy; **1.3)** Define what does it mean to design tech and CS thinking: what and if it is creativity as mirror of ethical principals?; **1.4)** define creativity as one of the possible considerations to take towards something *I* do inside the framework and that there should be a lot more of states that we can use that are not being creative; **2)** define future steps and possibilities to research ethics, to practice ethics and relate this to other ethics roles (as we did in all the text) (e.g maybe also at the governmental level; **3)** **Interfaces and establishing relationships between people and things?** embodied behavior and its limits for ethics (where our theory becomes virtual and link to haraway); **4)** *How do I relate to knowledge*, what it means to know or to cognise; with/to the whole body of historical philosophy, science, inquiry, and maybe AI and tech systems?

## Future work

Establish various points in which our theory can exist and be improved such as criticizing AIs that have no cognitive understanding of the world and yet we consider them - maybe connect this to the conscious experience. (e.g.) the fact that GPT-3 doesn't understand anything about the world and possible future steps in mathematics/CS to tackle virtual *understanding* **supervised grammar induction**, the meaning of the words... "The bat broke the window". How can we get to the fundamental meaning of a word that in itself is a map of a thinking we will never access in the current state of human civilization (multiple mind agency connected to the theory and its limits).